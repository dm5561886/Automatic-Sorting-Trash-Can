# Automatic-Sorting-Trash-Can
<h1>系統介紹</h1>
本系統利用 Google 提供的 AI 簡易機器人建構工具 Google Colaboratory，將其強大的運算能力整合至樹莓派中，並通過 Python 的函式庫技術進行引用。使用鏡頭和 cv2 技術對照片進行分析後，將結果導入 Python。透過 Python 的硬體模擬技術來驅動馬達進行自動分類。
分析結果會被應用到我們的網頁上，該網頁主要由 CSS、HTML 和 JavaScript 組成。AI 記錄的數據將存儲在 MySQL 中，並透過 PHP 將 MySQL 的數據導出到網頁上。我們的網頁還申請了域名並使用了 SSL 認證機制。
本系統採用主從式架構 (Client/Server) 提供服務。整個系統的運作機制完整，客戶端可以通過網際網路，使用瀏覽器操作前端所有與智慧分類垃圾桶系統相關的功能。使用者的資料會儲存在前端，伺服端和資料庫管理系統負責維持整個系統的運作。

<h1>人工智慧應用系統</h1>
1.進入系統  
  2.匯入圖片壓縮檔  
3.開始進行分析
4.將圖片的 80% 作為訓練資料，20% 作為測試資料
5.將訓練資料的數據進行交叉比對並透過一些分割圖片的方式細化
6.將 20% 的測試資料拿來套入並反覆進行交叉分析得到測試結果
7.測試 AI 的準確率與失敗率，持續反覆測試直到準確率提升至 98%
<h1>鏡頭擷取</h1>
在 Python 載入 cv2 模組和 time 模組
在 cv2 模組導入 cv2.VideoCapture
設定拍攝視窗長寬
設定檔案路徑
擷取畫面並存入檔案
<h1>動態偵測</h1>
在 Python 載入 cv2 模組和 time 模組
在 cv2 模組導入 cv2.VideoCapture
擷取靜止畫面時的圖片並以其為基準圖片
拍攝開始並將之後拍攝的照片當成測試圖片
將兩張圖片轉成黑白
將兩張圖片進行高斯模糊處理
擷取兩個圖片的差異
將兩張圖片進行二值化處理
使用 cv2.dilate 進行擴張處理，可避免當移動速度過快易不顯著時進行加強
抓取輪廓
取得圖形面積
將圖形面積存入陣列並透過 cv2.boundingRect 得出 x、y、w、h
將 xywh 與基礎圖片的 xywh 軸進行相減，若大於 1000 時則會觸發動態偵測，若小於 200 則不偵測
<h1>馬達控制</h1>
透過 Python 載入 RPI.GPIO 模組
導入 TIME 模組
建立函式來計算馬達的旋轉角度
設定 GPIO 的模式
設定 GPIO 的腳位
賦予每個腳位的變數
啟動腳位
設定四個模式的分類代號
輸入代號進行馬達轉動
<h1>數據分析</h1>
透過 Python 載入 tensorflow 模組、numpy 模組、math 模組
將圖片轉為一維陣列
將一維陣列轉為二維陣列
套入模組進行預測
得到預測答案
將答案取出
<h1>調整與改進</h1>
在實作過程中，鏡頭有時會出現辨識不靈敏或過於靈敏的問題。我們反覆調整辨識的數值，最終找到了最佳的設定，使系統能夠正常地進行辨識。
